{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:01:36.230680Z","iopub.execute_input":"2025-01-02T23:01:36.231144Z","iopub.status.idle":"2025-01-02T23:01:36.290163Z","shell.execute_reply.started":"2025-01-02T23:01:36.231107Z","shell.execute_reply":"2025-01-02T23:01:36.289053Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/jane-street-real-time-market-data-forecasting/responders.csv\n/kaggle/input/jane-street-real-time-market-data-forecasting/sample_submission.csv\n/kaggle/input/jane-street-real-time-market-data-forecasting/features.csv\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=4/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=5/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=6/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=3/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=1/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=8/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=2/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=0/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=7/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=9/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet/date_id=0/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet/date_id=0/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/jane_street_gateway.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/jane_street_inference_server.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/__init__.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/templates.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/relay.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/__init__.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/__init__.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"This notebook can only be run in kaggle, dataset is huge so we cannot download it . we use the kaggle resources to read dataset from there\nso before the start. please kindly add the input data from the right sight of the page and add dataset for JANE STREET REAL_TIME MARKET for this project as an input.\n\n","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport polars as pl\n\nimport kaggle_evaluation.jane_street_inference_server\n\n# Initialize a list to hold samples from each file\nsamples = []\n# Load a sample from each file\nfor i in range(10):\n    file_path = f\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id={i}/part-0.parquet\"\n    chunk = pd.read_parquet(file_path)\n    \n    # Take a sample of the data (adjust sample size as needed)\n    sample_chunk = chunk.sample(n=500000, random_state=42)  # For example, 100 rows\n    samples.append(sample_chunk)\n# Concatenate all samples into one DataFrame if needed\ndf = pd.concat(samples, ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:01:39.057966Z","iopub.execute_input":"2025-01-02T23:01:39.058285Z","iopub.status.idle":"2025-01-02T23:02:37.372463Z","shell.execute_reply.started":"2025-01-02T23:01:39.058262Z","shell.execute_reply":"2025-01-02T23:02:37.371264Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T21:46:40.148404Z","iopub.execute_input":"2025-01-02T21:46:40.148955Z","iopub.status.idle":"2025-01-02T21:46:40.924498Z","shell.execute_reply.started":"2025-01-02T21:46:40.148925Z","shell.execute_reply":"2025-01-02T21:46:40.923288Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"         date_id  time_id  symbol_id    weight  feature_00  feature_01  \\\n0             85      288         38  3.119714         NaN         NaN   \n1             83       69          0  2.372535         NaN         NaN   \n2             82      199         16  1.943764         NaN         NaN   \n3              0      779          9  2.285698         NaN         NaN   \n4            169      178          7  1.789037         NaN         NaN   \n...          ...      ...        ...       ...         ...         ...   \n4999995     1538      678         10  1.689046    5.308607   -2.340957   \n4999996     1666      619         20  1.113261   -0.157928   -0.568110   \n4999997     1645       22          7  2.865971    3.406640    0.219856   \n4999998     1573      326          2  2.036317    3.268634    0.391701   \n4999999     1581      868         13  3.119367    2.544981    0.225249   \n\n         feature_02  feature_03  feature_04  feature_05  ...  feature_78  \\\n0               NaN         NaN         NaN    0.188973  ...   -0.191460   \n1               NaN         NaN         NaN   -0.249393  ...   -0.304067   \n2               NaN         NaN         NaN   -0.034782  ...   -0.174753   \n3               NaN         NaN         NaN   -0.200830  ...   -0.264010   \n4               NaN         NaN         NaN    0.695718  ...   -0.256375   \n...             ...         ...         ...         ...  ...         ...   \n4999995    5.392371    4.964338   -1.005170   -1.115224  ...   -0.310852   \n4999996    0.342834    1.155595   -0.132432   -0.045609  ...   -0.777273   \n4999997    3.300762    2.901241    0.682474    0.874516  ...    0.350709   \n4999998    2.628897    3.175232    0.461267    1.447275  ...    0.086490   \n4999999    3.272773    2.927975    1.120015    2.798099  ...   -0.012830   \n\n         responder_0  responder_1  responder_2  responder_3  responder_4  \\\n0           0.386567    -0.180631    -0.394700     0.212311     1.695289   \n1           2.162238     0.687817     0.344059     2.191972     0.183375   \n2          -0.093317    -0.030093    -0.060351    -0.016916     0.141347   \n3          -0.010857    -0.047279     0.000333     0.223133     0.273011   \n4          -0.107448    -0.852934    -0.150064    -0.000850    -0.035807   \n...              ...          ...          ...          ...          ...   \n4999995    -0.078243     0.005706    -0.064333     0.476020     0.366925   \n4999996    -0.201261    -0.373656     0.120598     0.128131    -0.041448   \n4999997    -0.146070    -0.192120    -0.182462    -1.874103    -1.029148   \n4999998     0.178874     0.002081    -0.010340     0.228615    -0.201537   \n4999999     0.490120     0.859849    -2.559062     1.012663    -0.833926   \n\n         responder_5  responder_6  responder_7  responder_8  \n0          -0.002445    -0.041428     0.147673     0.352121  \n1           0.511344     1.261587    -0.337162     0.283835  \n2           0.084314     0.035796     0.130798     0.339303  \n3           0.259631     0.265585     0.200747    -0.067575  \n4          -0.328767     0.106589     0.703084    -0.247847  \n...              ...          ...          ...          ...  \n4999995     0.339919     0.559695     0.428870     0.797104  \n4999996     0.190805     0.570379     0.068017     0.399816  \n4999997    -1.979618    -1.961612    -0.878837    -2.385657  \n4999998    -0.349694     0.168292    -0.316983    -0.936698  \n4999999    -0.130829     1.196577    -1.337420     2.385221  \n\n[5000000 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>time_id</th>\n      <th>symbol_id</th>\n      <th>weight</th>\n      <th>feature_00</th>\n      <th>feature_01</th>\n      <th>feature_02</th>\n      <th>feature_03</th>\n      <th>feature_04</th>\n      <th>feature_05</th>\n      <th>...</th>\n      <th>feature_78</th>\n      <th>responder_0</th>\n      <th>responder_1</th>\n      <th>responder_2</th>\n      <th>responder_3</th>\n      <th>responder_4</th>\n      <th>responder_5</th>\n      <th>responder_6</th>\n      <th>responder_7</th>\n      <th>responder_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>85</td>\n      <td>288</td>\n      <td>38</td>\n      <td>3.119714</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.188973</td>\n      <td>...</td>\n      <td>-0.191460</td>\n      <td>0.386567</td>\n      <td>-0.180631</td>\n      <td>-0.394700</td>\n      <td>0.212311</td>\n      <td>1.695289</td>\n      <td>-0.002445</td>\n      <td>-0.041428</td>\n      <td>0.147673</td>\n      <td>0.352121</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>83</td>\n      <td>69</td>\n      <td>0</td>\n      <td>2.372535</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.249393</td>\n      <td>...</td>\n      <td>-0.304067</td>\n      <td>2.162238</td>\n      <td>0.687817</td>\n      <td>0.344059</td>\n      <td>2.191972</td>\n      <td>0.183375</td>\n      <td>0.511344</td>\n      <td>1.261587</td>\n      <td>-0.337162</td>\n      <td>0.283835</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>82</td>\n      <td>199</td>\n      <td>16</td>\n      <td>1.943764</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.034782</td>\n      <td>...</td>\n      <td>-0.174753</td>\n      <td>-0.093317</td>\n      <td>-0.030093</td>\n      <td>-0.060351</td>\n      <td>-0.016916</td>\n      <td>0.141347</td>\n      <td>0.084314</td>\n      <td>0.035796</td>\n      <td>0.130798</td>\n      <td>0.339303</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>779</td>\n      <td>9</td>\n      <td>2.285698</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.200830</td>\n      <td>...</td>\n      <td>-0.264010</td>\n      <td>-0.010857</td>\n      <td>-0.047279</td>\n      <td>0.000333</td>\n      <td>0.223133</td>\n      <td>0.273011</td>\n      <td>0.259631</td>\n      <td>0.265585</td>\n      <td>0.200747</td>\n      <td>-0.067575</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>169</td>\n      <td>178</td>\n      <td>7</td>\n      <td>1.789037</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.695718</td>\n      <td>...</td>\n      <td>-0.256375</td>\n      <td>-0.107448</td>\n      <td>-0.852934</td>\n      <td>-0.150064</td>\n      <td>-0.000850</td>\n      <td>-0.035807</td>\n      <td>-0.328767</td>\n      <td>0.106589</td>\n      <td>0.703084</td>\n      <td>-0.247847</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4999995</th>\n      <td>1538</td>\n      <td>678</td>\n      <td>10</td>\n      <td>1.689046</td>\n      <td>5.308607</td>\n      <td>-2.340957</td>\n      <td>5.392371</td>\n      <td>4.964338</td>\n      <td>-1.005170</td>\n      <td>-1.115224</td>\n      <td>...</td>\n      <td>-0.310852</td>\n      <td>-0.078243</td>\n      <td>0.005706</td>\n      <td>-0.064333</td>\n      <td>0.476020</td>\n      <td>0.366925</td>\n      <td>0.339919</td>\n      <td>0.559695</td>\n      <td>0.428870</td>\n      <td>0.797104</td>\n    </tr>\n    <tr>\n      <th>4999996</th>\n      <td>1666</td>\n      <td>619</td>\n      <td>20</td>\n      <td>1.113261</td>\n      <td>-0.157928</td>\n      <td>-0.568110</td>\n      <td>0.342834</td>\n      <td>1.155595</td>\n      <td>-0.132432</td>\n      <td>-0.045609</td>\n      <td>...</td>\n      <td>-0.777273</td>\n      <td>-0.201261</td>\n      <td>-0.373656</td>\n      <td>0.120598</td>\n      <td>0.128131</td>\n      <td>-0.041448</td>\n      <td>0.190805</td>\n      <td>0.570379</td>\n      <td>0.068017</td>\n      <td>0.399816</td>\n    </tr>\n    <tr>\n      <th>4999997</th>\n      <td>1645</td>\n      <td>22</td>\n      <td>7</td>\n      <td>2.865971</td>\n      <td>3.406640</td>\n      <td>0.219856</td>\n      <td>3.300762</td>\n      <td>2.901241</td>\n      <td>0.682474</td>\n      <td>0.874516</td>\n      <td>...</td>\n      <td>0.350709</td>\n      <td>-0.146070</td>\n      <td>-0.192120</td>\n      <td>-0.182462</td>\n      <td>-1.874103</td>\n      <td>-1.029148</td>\n      <td>-1.979618</td>\n      <td>-1.961612</td>\n      <td>-0.878837</td>\n      <td>-2.385657</td>\n    </tr>\n    <tr>\n      <th>4999998</th>\n      <td>1573</td>\n      <td>326</td>\n      <td>2</td>\n      <td>2.036317</td>\n      <td>3.268634</td>\n      <td>0.391701</td>\n      <td>2.628897</td>\n      <td>3.175232</td>\n      <td>0.461267</td>\n      <td>1.447275</td>\n      <td>...</td>\n      <td>0.086490</td>\n      <td>0.178874</td>\n      <td>0.002081</td>\n      <td>-0.010340</td>\n      <td>0.228615</td>\n      <td>-0.201537</td>\n      <td>-0.349694</td>\n      <td>0.168292</td>\n      <td>-0.316983</td>\n      <td>-0.936698</td>\n    </tr>\n    <tr>\n      <th>4999999</th>\n      <td>1581</td>\n      <td>868</td>\n      <td>13</td>\n      <td>3.119367</td>\n      <td>2.544981</td>\n      <td>0.225249</td>\n      <td>3.272773</td>\n      <td>2.927975</td>\n      <td>1.120015</td>\n      <td>2.798099</td>\n      <td>...</td>\n      <td>-0.012830</td>\n      <td>0.490120</td>\n      <td>0.859849</td>\n      <td>-2.559062</td>\n      <td>1.012663</td>\n      <td>-0.833926</td>\n      <td>-0.130829</td>\n      <td>1.196577</td>\n      <td>-1.337420</td>\n      <td>2.385221</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000000 rows × 92 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T21:46:45.040386Z","iopub.execute_input":"2025-01-02T21:46:45.040743Z","iopub.status.idle":"2025-01-02T21:47:08.397903Z","shell.execute_reply.started":"2025-01-02T21:46:45.040699Z","shell.execute_reply":"2025-01-02T21:47:08.396827Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"            date_id       time_id     symbol_id        weight    feature_00  \\\ncount  5.000000e+06  5.000000e+06  5.000000e+06  5.000000e+06  4.279433e+06   \nmean   8.515916e+02  4.597232e+02  1.745508e+01  1.961934e+00  5.141348e-01   \nstd    4.888908e+02  2.678890e+02  1.132409e+01  1.109640e+00  1.293203e+00   \nmin    0.000000e+00  0.000000e+00  0.000000e+00  1.499667e-01 -4.896503e+00   \n25%    4.300000e+02  2.290000e+02  8.000000e+00  1.182066e+00 -3.578772e-01   \n50%    8.495000e+02  4.580000e+02  1.600000e+01  1.709349e+00  3.775473e-01   \n75%    1.275000e+03  6.870000e+02  2.700000e+01  2.444289e+00  1.205093e+00   \nmax    1.698000e+03  9.670000e+02  3.800000e+01  1.024042e+01  6.306120e+00   \n\n         feature_01    feature_02    feature_03    feature_04    feature_05  \\\ncount  4.279433e+06  4.279433e+06  4.279433e+06  4.279433e+06  5.000000e+06   \nmean   9.585897e-03  5.138597e-01  5.131920e-01 -2.346339e-03 -2.839112e-02   \nstd    1.067698e+00  1.289396e+00  1.289199e+00  1.027625e+00  1.018968e+00   \nmin   -5.408048e+00 -5.401776e+00 -5.006516e+00 -5.662611e+00 -2.288654e+01   \n25%   -7.043812e-01 -3.550577e-01 -3.562764e-01 -6.990829e-01 -4.807177e-01   \n50%    5.645112e-03  3.790944e-01  3.786045e-01  2.344981e-04 -5.037843e-02   \n75%    7.141013e-01  1.204020e+00  1.203336e+00  6.942484e-01  3.962759e-01   \nmax    6.054423e+00  6.374411e+00  6.249628e+00  5.889555e+00  3.327213e+01   \n\n       ...    feature_78   responder_0   responder_1   responder_2  \\\ncount  ...  4.998263e+06  5.000000e+06  5.000000e+06  5.000000e+06   \nmean   ... -1.479100e-02 -1.031707e-03  5.517127e-04 -3.875554e-04   \nstd    ...  9.314567e-01  6.504011e-01  6.701173e-01  6.497288e-01   \nmin    ... -6.159515e+00 -5.000000e+00 -5.000000e+00 -5.000000e+00   \n25%    ... -3.063939e-01 -1.996855e-01 -1.748308e-01 -1.989229e-01   \n50%    ... -2.007968e-01 -4.649878e-03 -2.386631e-02 -9.935633e-04   \n75%    ...  4.000021e-02  1.914179e-01  1.402529e-01  1.976444e-01   \nmax    ...  1.936215e+02  5.000000e+00  5.000000e+00  5.000000e+00   \n\n        responder_3   responder_4   responder_5   responder_6   responder_7  \\\ncount  5.000000e+06  5.000000e+06  5.000000e+06  5.000000e+06  5.000000e+06   \nmean  -1.267402e-02 -8.344845e-03 -1.334051e-02 -2.105973e-03  5.507753e-04   \nstd    8.615133e-01  9.178677e-01  7.778510e-01  8.978214e-01  9.242541e-01   \nmin   -5.000000e+00 -5.000000e+00 -5.000000e+00 -5.000000e+00 -5.000000e+00   \n25%   -3.228640e-01 -3.968892e-01 -2.303678e-01 -3.857883e-01 -4.221829e-01   \n50%   -2.403990e-02 -4.097726e-02 -8.744015e-03 -2.314510e-02 -3.598790e-02   \n75%    2.785214e-01  3.354963e-01  2.075475e-01  3.412049e-01  3.625524e-01   \nmax    5.000000e+00  5.000000e+00  5.000000e+00  5.000000e+00  5.000000e+00   \n\n        responder_8  \ncount  5.000000e+06  \nmean  -1.398112e-03  \nstd    8.761280e-01  \nmin   -5.000000e+00  \n25%   -3.353128e-01  \n50%   -7.194911e-03  \n75%    3.147683e-01  \nmax    5.000000e+00  \n\n[8 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>time_id</th>\n      <th>symbol_id</th>\n      <th>weight</th>\n      <th>feature_00</th>\n      <th>feature_01</th>\n      <th>feature_02</th>\n      <th>feature_03</th>\n      <th>feature_04</th>\n      <th>feature_05</th>\n      <th>...</th>\n      <th>feature_78</th>\n      <th>responder_0</th>\n      <th>responder_1</th>\n      <th>responder_2</th>\n      <th>responder_3</th>\n      <th>responder_4</th>\n      <th>responder_5</th>\n      <th>responder_6</th>\n      <th>responder_7</th>\n      <th>responder_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.000000e+06</td>\n      <td>5.000000e+06</td>\n      <td>5.000000e+06</td>\n      <td>5.000000e+06</td>\n      <td>4.279433e+06</td>\n      <td>4.279433e+06</td>\n      <td>4.279433e+06</td>\n      <td>4.279433e+06</td>\n      <td>4.279433e+06</td>\n      <td>5.000000e+06</td>\n      <td>...</td>\n      <td>4.998263e+06</td>\n      <td>5.000000e+06</td>\n      <td>5.000000e+06</td>\n      <td>5.000000e+06</td>\n      <td>5.000000e+06</td>\n      <td>5.000000e+06</td>\n      <td>5.000000e+06</td>\n      <td>5.000000e+06</td>\n      <td>5.000000e+06</td>\n      <td>5.000000e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>8.515916e+02</td>\n      <td>4.597232e+02</td>\n      <td>1.745508e+01</td>\n      <td>1.961934e+00</td>\n      <td>5.141348e-01</td>\n      <td>9.585897e-03</td>\n      <td>5.138597e-01</td>\n      <td>5.131920e-01</td>\n      <td>-2.346339e-03</td>\n      <td>-2.839112e-02</td>\n      <td>...</td>\n      <td>-1.479100e-02</td>\n      <td>-1.031707e-03</td>\n      <td>5.517127e-04</td>\n      <td>-3.875554e-04</td>\n      <td>-1.267402e-02</td>\n      <td>-8.344845e-03</td>\n      <td>-1.334051e-02</td>\n      <td>-2.105973e-03</td>\n      <td>5.507753e-04</td>\n      <td>-1.398112e-03</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.888908e+02</td>\n      <td>2.678890e+02</td>\n      <td>1.132409e+01</td>\n      <td>1.109640e+00</td>\n      <td>1.293203e+00</td>\n      <td>1.067698e+00</td>\n      <td>1.289396e+00</td>\n      <td>1.289199e+00</td>\n      <td>1.027625e+00</td>\n      <td>1.018968e+00</td>\n      <td>...</td>\n      <td>9.314567e-01</td>\n      <td>6.504011e-01</td>\n      <td>6.701173e-01</td>\n      <td>6.497288e-01</td>\n      <td>8.615133e-01</td>\n      <td>9.178677e-01</td>\n      <td>7.778510e-01</td>\n      <td>8.978214e-01</td>\n      <td>9.242541e-01</td>\n      <td>8.761280e-01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.499667e-01</td>\n      <td>-4.896503e+00</td>\n      <td>-5.408048e+00</td>\n      <td>-5.401776e+00</td>\n      <td>-5.006516e+00</td>\n      <td>-5.662611e+00</td>\n      <td>-2.288654e+01</td>\n      <td>...</td>\n      <td>-6.159515e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.300000e+02</td>\n      <td>2.290000e+02</td>\n      <td>8.000000e+00</td>\n      <td>1.182066e+00</td>\n      <td>-3.578772e-01</td>\n      <td>-7.043812e-01</td>\n      <td>-3.550577e-01</td>\n      <td>-3.562764e-01</td>\n      <td>-6.990829e-01</td>\n      <td>-4.807177e-01</td>\n      <td>...</td>\n      <td>-3.063939e-01</td>\n      <td>-1.996855e-01</td>\n      <td>-1.748308e-01</td>\n      <td>-1.989229e-01</td>\n      <td>-3.228640e-01</td>\n      <td>-3.968892e-01</td>\n      <td>-2.303678e-01</td>\n      <td>-3.857883e-01</td>\n      <td>-4.221829e-01</td>\n      <td>-3.353128e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>8.495000e+02</td>\n      <td>4.580000e+02</td>\n      <td>1.600000e+01</td>\n      <td>1.709349e+00</td>\n      <td>3.775473e-01</td>\n      <td>5.645112e-03</td>\n      <td>3.790944e-01</td>\n      <td>3.786045e-01</td>\n      <td>2.344981e-04</td>\n      <td>-5.037843e-02</td>\n      <td>...</td>\n      <td>-2.007968e-01</td>\n      <td>-4.649878e-03</td>\n      <td>-2.386631e-02</td>\n      <td>-9.935633e-04</td>\n      <td>-2.403990e-02</td>\n      <td>-4.097726e-02</td>\n      <td>-8.744015e-03</td>\n      <td>-2.314510e-02</td>\n      <td>-3.598790e-02</td>\n      <td>-7.194911e-03</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.275000e+03</td>\n      <td>6.870000e+02</td>\n      <td>2.700000e+01</td>\n      <td>2.444289e+00</td>\n      <td>1.205093e+00</td>\n      <td>7.141013e-01</td>\n      <td>1.204020e+00</td>\n      <td>1.203336e+00</td>\n      <td>6.942484e-01</td>\n      <td>3.962759e-01</td>\n      <td>...</td>\n      <td>4.000021e-02</td>\n      <td>1.914179e-01</td>\n      <td>1.402529e-01</td>\n      <td>1.976444e-01</td>\n      <td>2.785214e-01</td>\n      <td>3.354963e-01</td>\n      <td>2.075475e-01</td>\n      <td>3.412049e-01</td>\n      <td>3.625524e-01</td>\n      <td>3.147683e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.698000e+03</td>\n      <td>9.670000e+02</td>\n      <td>3.800000e+01</td>\n      <td>1.024042e+01</td>\n      <td>6.306120e+00</td>\n      <td>6.054423e+00</td>\n      <td>6.374411e+00</td>\n      <td>6.249628e+00</td>\n      <td>5.889555e+00</td>\n      <td>3.327213e+01</td>\n      <td>...</td>\n      <td>1.936215e+02</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 92 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# to see duplicated values:","metadata":{}},{"cell_type":"code","source":"df[df.duplicated(subset=['symbol_id', 'date_id', 'time_id'])]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T20:21:54.371228Z","iopub.execute_input":"2025-01-02T20:21:54.371477Z","iopub.status.idle":"2025-01-02T20:21:55.246378Z","shell.execute_reply.started":"2025-01-02T20:21:54.371455Z","shell.execute_reply":"2025-01-02T20:21:55.245141Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [date_id, time_id, symbol_id, weight, feature_00, feature_01, feature_02, feature_03, feature_04, feature_05, feature_06, feature_07, feature_08, feature_09, feature_10, feature_11, feature_12, feature_13, feature_14, feature_15, feature_16, feature_17, feature_18, feature_19, feature_20, feature_21, feature_22, feature_23, feature_24, feature_25, feature_26, feature_27, feature_28, feature_29, feature_30, feature_31, feature_32, feature_33, feature_34, feature_35, feature_36, feature_37, feature_38, feature_39, feature_40, feature_41, feature_42, feature_43, feature_44, feature_45, feature_46, feature_47, feature_48, feature_49, feature_50, feature_51, feature_52, feature_53, feature_54, feature_55, feature_56, feature_57, feature_58, feature_59, feature_60, feature_61, feature_62, feature_63, feature_64, feature_65, feature_66, feature_67, feature_68, feature_69, feature_70, feature_71, feature_72, feature_73, feature_74, feature_75, feature_76, feature_77, feature_78, responder_0, responder_1, responder_2, responder_3, responder_4, responder_5, responder_6, responder_7, responder_8]\nIndex: []\n\n[0 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>time_id</th>\n      <th>symbol_id</th>\n      <th>weight</th>\n      <th>feature_00</th>\n      <th>feature_01</th>\n      <th>feature_02</th>\n      <th>feature_03</th>\n      <th>feature_04</th>\n      <th>feature_05</th>\n      <th>...</th>\n      <th>feature_78</th>\n      <th>responder_0</th>\n      <th>responder_1</th>\n      <th>responder_2</th>\n      <th>responder_3</th>\n      <th>responder_4</th>\n      <th>responder_5</th>\n      <th>responder_6</th>\n      <th>responder_7</th>\n      <th>responder_8</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 92 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"\n# In orderr to deal with outliers## \n","metadata":{}},{"cell_type":"code","source":"\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm  # Import tqdm for progress bar\n\n# Grouping and processing per symbol_id\nunique_symbol_ids = df['symbol_id'].unique()  # Unique symbol IDs\nselected_columns = df.filter(regex='^feature_').columns  # Columns matching 'feature_' pattern\n\n# Wrap the main loop with tqdm for a progress bar\nfor symbol_id in tqdm(unique_symbol_ids, desc=\"Processing symbols\"):\n    # Filter data for the current symbol\n    symbol_group = df[df['symbol_id'] == symbol_id]\n\n    # Iterate over the selected columns\n    for column in selected_columns:\n        # Skip if the column is missing in the current group\n        if column not in symbol_group.columns:\n            continue\n        \n        # Check if the column contains non-NaN values\n        if symbol_group[column].notna().sum() == 0:\n            continue\n        \n        # Calculate mean and std for the current column within the group\n        mean = symbol_group[column].mean(skipna=True)\n        std = symbol_group[column].std(skipna=True)\n        \n        # Skip if std or mean cannot be computed (e.g., insufficient data)\n        if np.isnan(std) or np.isnan(mean):\n            continue\n        \n        # Calculate Z-scores\n        z_scores = (symbol_group[column] - mean) / std\n        \n        # Detect outliers (Z-score > 3 or < -3)\n        outliers = np.abs(z_scores) > 3\n        \n        # Replace outliers with the median of the column within the group\n        median_value = symbol_group[column].median(skipna=True)\n        df.loc[symbol_group.index[outliers], column] = median_value\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:02:53.635631Z","iopub.execute_input":"2025-01-02T23:02:53.636123Z","iopub.status.idle":"2025-01-02T23:03:13.490482Z","shell.execute_reply.started":"2025-01-02T23:02:53.636083Z","shell.execute_reply":"2025-01-02T23:03:13.489418Z"}},"outputs":[{"name":"stderr","text":"Processing symbols: 100%|██████████| 39/39 [00:19<00:00,  2.03it/s]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# to see nan values in our dataset:#\n","metadata":{}},{"cell_type":"code","source":"df.isna().sum().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T20:22:14.386919Z","iopub.execute_input":"2025-01-02T20:22:14.387166Z","iopub.status.idle":"2025-01-02T20:22:14.941949Z","shell.execute_reply.started":"2025-01-02T20:22:14.387145Z","shell.execute_reply":"2025-01-02T20:22:14.940864Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"13391797"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# Nan values and replacing them with the mean of the amount in each day for each symbol: this step is time consuming\n","metadata":{}},{"cell_type":"code","source":"def fill_nan_by_group_mean(group):\n\n    \n    row_mean = group.mean(axis=1)\n    \n    return group.apply(lambda col: col.fillna(row_mean), axis=0)\n\n\ndf = df.groupby(['symbol_id', 'date_id'], group_keys=False).apply(fill_nan_by_group_mean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:03:22.025735Z","iopub.execute_input":"2025-01-02T23:03:22.026140Z","iopub.status.idle":"2025-01-02T23:17:15.334101Z","shell.execute_reply.started":"2025-01-02T23:03:22.026110Z","shell.execute_reply":"2025-01-02T23:17:15.332714Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df.isna().sum().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T20:36:20.300125Z","iopub.execute_input":"2025-01-02T20:36:20.300454Z","iopub.status.idle":"2025-01-02T20:36:20.892921Z","shell.execute_reply.started":"2025-01-02T20:36:20.300415Z","shell.execute_reply":"2025-01-02T20:36:20.891894Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# so there is no more Nan values\n","metadata":{}},{"cell_type":"markdown","source":"# The model that works for the whole dataset and is the prefered one LSTM:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dropout, Dense\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the weighted R^2 function\ndef weighted_r2(y_true, y_pred, weights):\n\n    # Weighted RSS (Residual Sum of Squares)\n    weighted_rss = np.sum(weights * (y_true - y_pred)**2)\n\n    weighted_tss = np.sum(weights * (y_true )**2)   \n    # Weighted R^2\n    r2_weighted = 1 - (weighted_rss / weighted_tss)\n    \n    return r2_weighted\n\n# Preprocess data\nfeatures = df.filter(regex='^feature_')  # Extract feature columns\nresponders = df.filter(regex='^responder_')  # Extract responder columns\nweights = df['weight']  # Extract weights column\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled_features = scaler.fit_transform(features)\nscaled_responders = scaler.fit_transform(responders)\n\nX = scaled_features  # Features for input\ny = scaled_responders[:, 5]  # Keep only 'responder_6'\nweights = weights.values  # Convert weights to numpy array if needed\n\n# Reshape X for LSTM input (3D input: [samples, timesteps, features])\nX = X.reshape(X.shape[0], X.shape[1], 1)\n\n# Split the data\nX_train, X_valid, y_train, y_valid, w_train, w_valid = train_test_split(\n    X, y, weights, test_size=0.2, random_state=42\n)\n\n# Reshape data for LSTM input (ensure your data is 3D: [samples, timesteps, features])\nX_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\nX_valid_reshaped = X_valid.reshape((X_valid.shape[0], X_valid.shape[1], 1))\n\n# Build the LSTM Model\nmodel = Sequential()\n\n# Add LSTM layers and Dropout layers\nmodel.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=60, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(units=80, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.4))\nmodel.add(LSTM(units=120, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# Add output layer\nmodel.add(Dense(units=1))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Define ModelCheckpoint callback\nmodel_save = \"/kaggle/working/stock_model.keras\"\ncheckpoint = ModelCheckpoint(\n    filepath=model_save,\n    monitor='val_loss',\n    save_best_only=True,\n    verbose=1\n)\n\n# Train the model using actual sample weights from your data\nhistory = model.fit(\n    X_train_reshaped,\n    y_train,\n    sample_weight=w_train,  # Pass actual sample weights for training\n    validation_data=(X_valid_reshaped, y_valid, w_valid),  # Pass actual sample weights for validation\n    epochs=1,\n    batch_size=64,\n    verbose=1,\n    callbacks=[checkpoint]\n)\n\n# Plot training and validation loss\n# plt.figure(figsize=(10, 5))\n# plt.plot(history.history['loss'], label='Training Loss')\n# plt.plot(history.history['val_loss'], label='Validation Loss')\n# plt.xlabel('Epoch')\n# plt.ylabel('Loss')\n# plt.title('Training and Validation Loss')\n# plt.legend(loc='upper right')\n# plt.grid(True)\n# plt.show()\n\n# Make predictions on validation data\ny_pred = model.predict(X_valid_reshaped).flatten()\n\n# Calculate Normal RMSE (sklearn)\nnormal_rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n\n# Calculate Weighted RMSE using the custom weighted_rmse function\nmse_weighted = mean_squared_error(y_valid, y_pred, sample_weight=w_valid)\nrmse_weighted = np.sqrt(mse_weighted)\nprint(f\"Weighted MSE : {mse_weighted:.4f}\")  \n\n# Print both Normal RMSE and Weighted RMSE\nprint(f\"Normal RMSE on Validation Set: {normal_rmse:.4f}\")\nprint(f\"Weighted RMSE on Validation Set: {rmse_weighted:.4f}\")\n\n# Calculate and print Weighted R^2 on Validation Set\nweighted_r2_score = weighted_r2(y_valid, y_pred, w_valid)\nprint(f\"Weighted R^2 on Validation Set: {weighted_r2_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:17:31.919637Z","iopub.execute_input":"2025-01-02T23:17:31.920081Z","iopub.status.idle":"2025-01-03T04:07:43.178316Z","shell.execute_reply.started":"2025-01-02T23:17:31.920030Z","shell.execute_reply":"2025-01-03T04:07:43.175828Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.0121\nEpoch 1: val_loss improved from inf to 0.01066, saving model to /kaggle/working/stock_model.keras\n\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15426s\u001b[0m 247ms/step - loss: 0.0121 - val_loss: 0.0107\n\u001b[1m31250/31250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1941s\u001b[0m 62ms/step\nWeighted MSE : 0.0054\nNormal RMSE on Validation Set: 0.0777\nWeighted RMSE on Validation Set: 0.0737\nWeighted R^2 on Validation Set: 0.9786\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-02T19:54:38.819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}